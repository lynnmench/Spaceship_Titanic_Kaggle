Author: Lynn Menchaca
Start Date: 15Apr2022

# Kaggle Spaceship Titanic
The purpose of this project is to predict which passengers were transported off the Spaceship Titanic after it collided with a spacetime anomaly hidden within a dust cloud. Kaggle provides the traning data file with personal information for about 2/3rd the passengers on board (about 8700 people), along with if they were transported or not. Kaggle aslo provides the test data file, to be used with your machine learning model to predict which of the remaining 1/3rd passengers were transported. The passenger ID and transported status from the test data file is submitted in the Kaggle competition.

#### -- Project Status: Active

## Project Overview
### Resources
Kaggle Competition: [Spaceship Titanic] (https://www.kaggle.com/competitions/spaceship-titanic/overview)

ReadMe Templet:
RocioSNg, Update Project-README-template.md
https://github.com/sfbrigade/data-science-wg/blob/master/dswg_project_resources/Project-README-template.md

### Language/Platform/Libraries
* Python
* Jupyter
* Spyder
* Pandas
* numpy
* matplotlib
* sklearn

### Project Outline
* Inferential Statistics
* 
* Machine Learning
* Data Visualization
* Predictive Modeling
* etc.
* - frontend developers
- data exploration/descriptive statistics
- data processing/cleaning
- statistical modeling
- writeup/reporting
- etc. (be as specific as possible)


## Project Description

(Provide more detailed overview of the project.  Talk a bit about your data sources and what questions and hypothesis you are exploring. What specific data analysis/visualization and modelling work are you using to solve the problem? What blockers and challenges are you facing?  Feel free to number or bullet point things here)

### Data Cleaning and Analysis


### 
1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data is being kept [here](Repo folder containing raw data) within this repo.

    *If using offline data mention that and how they may obtain the data from the froup)*
    
3. Data processing/transformation scripts are being kept [here](Repo folder containing data processing scripts/notebooks)
4. etc...

*If your project is well underway and setup is fairly complicated (ie. requires installation of many packages) create another "setup.md" file and link to it here*  

5. Follow setup [instructions](Link to file)

## Featured Notebooks/Analysis/Deliverables
* [Notebook/Markdown/Slide Deck Title](link)
* [Notebook/Markdown/Slide DeckTitle](link)
* [Blog Post](link)
